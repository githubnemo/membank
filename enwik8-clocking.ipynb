{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import enwik8_data\n",
    "import imp\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = enwik8_data.hutter_raw_data(data_path='./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA, VALID_DATA, TEST_DATA, unique_syms = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = len(unique_syms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collate(g):\n",
    "    for x, y in g:\n",
    "        yield torch.from_numpy(x).long(), torch.from_numpy(y).long()\n",
    "\n",
    "class Enwik8Loader:\n",
    "    def __init__(self, _dataset, batch_size=128, num_steps=32, max_samples=None, **kwargs):\n",
    "        self.max_samples = max_samples\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "    def __iter__(self):\n",
    "        return collate(enwik8_data.data_iterator(\n",
    "            self.dataset[slice(0, self.max_samples)], \n",
    "            self.batch_size, \n",
    "            self.num_steps))\n",
    "\n",
    "class Enwik8TrainLoader(Enwik8Loader):\n",
    "    dataset = TRAIN_DATA\n",
    "    \n",
    "class Enwik8ValidLoader:\n",
    "    dataset = VALID_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_flatten(t):\n",
    "    return t.view(t.size(0) * t.size(1), -1)\n",
    "\n",
    "def time_unflatten(t, s):\n",
    "    return t.view(s[0], s[1], -1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "class ReconModel(nn.Module):\n",
    "    def __init__(self, num_hidden=64, num_modules=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(EMBEDDING_SIZE, num_hidden)\n",
    "        self.rnn = models.SurprisalCWRNN(num_hidden, num_hidden, num_modules)\n",
    "        self.clf = nn.Linear(num_hidden, EMBEDDING_SIZE)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_emb = self.emb(x.long())\n",
    "        l0, h0 = self.rnn(x_emb)\n",
    "        \n",
    "        vis.heatmap(l0[0].data.cpu().numpy(), win=\"act\")\n",
    "        vis.heatmap(self.rnn.module_periods.data.cpu().numpy().reshape(1, -1), win=\"periods\")\n",
    "        vis.heatmap(self.rnn.module_shifts.data.cpu().numpy().reshape(1, -1), win=\"shifts\")\n",
    "\n",
    "        l1 = self.clf(time_flatten(l0))\n",
    "        l1_sm = self.softmax(l1)\n",
    "        \n",
    "        return time_unflatten(l1_sm, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReconModel(nn.Module):\n",
    "    def __init__(self, num_hidden=64, num_modules=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(EMBEDDING_SIZE, num_hidden)\n",
    "        self.rnn = models.SurprisalCWRNN(num_hidden, num_hidden, num_modules)\n",
    "        self.clf = nn.Linear(num_hidden, EMBEDDING_SIZE)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_emb = self.emb(x.long())\n",
    "        l0, h0, m0 = self.rnn(x_emb)\n",
    "        \n",
    "        vis.heatmap(l0[0].data.cpu().numpy(), win=\"act\")\n",
    "        vis.heatmap(m0[0].data.cpu().numpy(), win=\"periods\")\n",
    "        vis.heatmap(self.rnn.module_shifts.data.cpu().numpy().reshape(1, -1), win=\"shifts\")\n",
    "\n",
    "        l1 = self.clf(time_flatten(l0))\n",
    "        l1_sm = self.softmax(l1)\n",
    "        \n",
    "        return time_unflatten(l1_sm, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer(skorch.NeuralNet):\n",
    "    def __init__(self, \n",
    "                 criterion=nn.NLLLoss,\n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        super().__init__(*args, criterion=criterion, **kwargs)\n",
    "\n",
    "    def get_loss(self, y_pred, y_true, X=None, train=False):\n",
    "        pred = time_flatten(y_pred)\n",
    "        true = time_flatten(y_true).squeeze(-1)\n",
    "        return super().get_loss(pred, true, X=X, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "class BatchPrinter(skorch.callbacks.Callback):\n",
    "    def __init__(self, update_interval=5):\n",
    "        self.batches_per_epoch = None\n",
    "        self.batch_counter = 0\n",
    "        self.update_interval = update_interval\n",
    "    def on_batch_begin(self, *args, **kwargs):\n",
    "        self.batch_start_time = time.time()\n",
    "    def on_batch_end(self, net, *args, train=True, **kwargs):\n",
    "        self.batch_end_time = time.time()\n",
    "        self.batch_counter += 1\n",
    "        if self.batch_counter % self.update_interval != 0:\n",
    "            return\n",
    "        \n",
    "        k = 'train_loss' if train else 'valid_loss'\n",
    "        loss = '{}: {:.3}'.format(k, net.history[-1, 'batches', -1, k])\n",
    "        \n",
    "        sys.stdout.write(\"Batch {}/{} complete ({:.2}s), {}.\\r\".format(\n",
    "            self.batch_counter, \n",
    "            self.batches_per_epoch,\n",
    "            self.batch_end_time - self.batch_start_time,\n",
    "            loss,\n",
    "        ))\n",
    "        sys.stdout.flush()\n",
    "    def on_epoch_end(self, *args, **kwargs):\n",
    "        if self.batches_per_epoch is None:\n",
    "            self.batches_per_epoch = self.batch_counter\n",
    "        self.batch_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "ef = Trainer(module=ReconModel,\n",
    "             optim=torch.optim.Adam,\n",
    "             lr=0.005,\n",
    "             max_epochs=5,\n",
    "                  \n",
    "             train_split=None,\n",
    "             iterator_train=Enwik8TrainLoader,\n",
    "             iterator_train__batch_size=32,\n",
    "             iterator_train__num_steps=32,\n",
    "             iterator_test=Enwik8ValidLoader,\n",
    "             iterator_test__batch_size=32,\n",
    "             iterator_test__num_steps=32,\n",
    "             \n",
    "             use_cuda=True,\n",
    "             \n",
    "             module__num_modules=8,\n",
    "             module__num_hidden=64,\n",
    "             \n",
    "             callbacks=[BatchPrinter()]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/nemo/Code/pytorch/work/membank/models.py'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp; imp.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "  epoch    train_loss         dur, train_loss: 2.18.\n",
      "-------  ------------  ----------\n",
      "      1        \u001b[36m2.0787\u001b[0m  16946.4112\n",
      "      2        2.1018  16848.5859), train_loss: 2.14.\n",
      "Exception in user code:ete (0.18s), train_loss: 2.11.\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/visdom/__init__.py\", line 240, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/api.py\", line 112, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/api.py\", line 58, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/adapters.py\", line 440, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/connectionpool.py\", line 601, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/connectionpool.py\", line 357, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/util/connection.py\", line 60, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "  File \"/usr/lib/python3.5/socket.py\", line 732, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:ete (0.23s), train_loss: 2.27.\n",
      "------------------------------------------------------------\n",
      "Batch 35415/87890 complete (0.2s), train_loss: 2.13.\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/visdom/__init__.py\", line 240, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/api.py\", line 112, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/api.py\", line 58, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/sessions.py\", line 508, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/sessions.py\", line 618, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/adapters.py\", line 405, in send\n",
      "    conn = self.get_connection(request.url, proxies)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/requests/adapters.py\", line 309, in get_connection\n",
      "    conn = self.poolmanager.connection_from_url(url)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/poolmanager.py\", line 279, in connection_from_url\n",
      "    pool_kwargs=pool_kwargs)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/poolmanager.py\", line 227, in connection_from_host\n",
      "    return self.connection_from_context(request_context)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/poolmanager.py\", line 240, in connection_from_context\n",
      "    return self.connection_from_pool_key(pool_key, request_context=request_context)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/poolmanager.py\", line 261, in connection_from_pool_key\n",
      "    pool = self._new_pool(scheme, host, port, request_context=request_context)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/poolmanager.py\", line 195, in _new_pool\n",
      "    return pool_cls(host, port, **request_context)\n",
      "  File \"/home/nemo/Code/pytorch/env/lib/python3.5/site-packages/urllib3/connectionpool.py\", line 189, in __init__\n",
      "    self.pool.put(None)\n",
      "  File \"/usr/lib/python3.5/queue.py\", line 145, in put\n",
      "    self.not_empty.notify()\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 342, in notify\n",
      "    if not self._is_owned():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Trainer at 0x7fba520ef7f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pdb on\n",
    "ef.fit(torch.zeros((10,1)), torch.zeros((10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clocking CWRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "  epoch    train_loss         dur, train_loss: 2.38..\n",
      "-------  ------------  ----------\n",
      "      1        \u001b[36m2.3205\u001b[0m  10506.3287\n",
      "      2        \u001b[36m2.2261\u001b[0m  10184.8781loss: 2.11..\n",
      "      3        \u001b[36m2.0944\u001b[0m  10190.3140loss: 2.15..\n",
      "      4        2.1289  10192.3899), train_loss: 2.16..\n",
      "      5        2.1656  10702.8350), train_loss: 2.22..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Trainer at 0x7fba66043ac8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pdb on\n",
    "ef.fit(torch.zeros((10,1)), torch.zeros((10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
