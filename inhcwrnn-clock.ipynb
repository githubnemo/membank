{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inferno\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sine_data import train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import insp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_dataset(points=200)\n",
    "X_train, y_train = torch.Tensor(X_train), torch.LongTensor(y_train)\n",
    "\n",
    "X_valid, y_valid = valid_dataset(points=400)\n",
    "X_valid, y_valid = torch.Tensor(X_valid), torch.LongTensor(y_valid)\n",
    "\n",
    "sine_train_loader = DataLoader(TensorDataset(X_train, y_train),\n",
    "                               batch_size=64,\n",
    "                               shuffle=True)\n",
    "sine_valid_loader = DataLoader(TensorDataset(X_valid, y_valid),\n",
    "                               batch_size=64,\n",
    "                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InhCWRNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_modules, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_modules = num_modules\n",
    "        \n",
    "        self.input_mod = nn.Linear(input_dim, output_dim)\n",
    "        self.hidden_mod = nn.Linear(output_dim, output_dim, bias=False)\n",
    "        \n",
    "        #self.module_periods = nn.Parameter(torch.zeros(output_dim) + 1)\n",
    "        #self.module_shifts = nn.Parameter(torch.zeros(output_dim))\n",
    "        self.module_periods = nn.Parameter(torch.zeros(num_modules) + 1)\n",
    "        self.module_shifts = nn.Parameter(torch.zeros(num_modules))\n",
    "        \n",
    "        self.f_mod = nn.Tanh()        \n",
    "        \n",
    "    def step(self, ti, xi, h):\n",
    "        module_size = self.output_dim // self.num_modules\n",
    "        \n",
    "        acts = self.f_mod(self.input_mod(xi) + self.hidden_mod(h))\n",
    "        module_acts = acts.view(-1, self.num_modules, module_size)\n",
    "                \n",
    "        gate = torch.sin(ti * self.module_periods + self.module_shifts)\n",
    "        gate = gate.view(1, -1, 1).expand_as(module_acts).contiguous()\n",
    "        gate = gate.view(-1, self.output_dim)\n",
    "                \n",
    "        y = (1 - gate) * acts + gate * h\n",
    "        \n",
    "        return y, y\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.output_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        t = x.size(1)\n",
    "        ys = []\n",
    "        h = self.init_hidden()\n",
    "        for ti in range(t):\n",
    "            xi = x[:, ti]\n",
    "            yi, h = self.step(ti, xi, h)            \n",
    "            ys.append(yi)\n",
    "        return torch.stack(ys, dim=1), h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_flatten(t):\n",
    "    return t.view(t.size(0) * t.size(1), -1)\n",
    "\n",
    "def time_unflatten(t, s):\n",
    "    return t.view(s[0], s[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconModel(nn.Module):\n",
    "    def __init__(self, num_hidden=64, num_modules=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = InhCWRNN(1, num_hidden, num_modules)\n",
    "        self.clf = nn.Linear(num_hidden, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        l0, h0 = self.rnn(x)\n",
    "        \n",
    "        vis.heatmap(l0[0].data.numpy(), win=\"act\")\n",
    "        vis.heatmap(self.rnn.module_periods.data.numpy().reshape(1, -1), win=\"periods\")\n",
    "        vis.heatmap(self.rnn.module_shifts.data.numpy().reshape(1, -1), win=\"shifts\")\n",
    "\n",
    "        l1 = self.clf(time_flatten(l0))\n",
    "        return time_unflatten(l1, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer(inferno.NeuralNet):\n",
    "    def __init__(self, \n",
    "                 criterion=nn.MSELoss,\n",
    "                 *args, \n",
    "                 **kwargs):\n",
    "        super().__init__(*args, criterion=criterion, **kwargs)\n",
    "\n",
    "    def get_loss(self, y_pred, y_true, X=None, train=False):\n",
    "        pred = time_flatten(y_pred)\n",
    "        true = time_flatten(y_true)\n",
    "        return super().get_loss(pred, true, X=X, train=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exp inhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "def my_train_split(X, y):\n",
    "    return X, X_valid[:, :-1], y, X_valid[:, 1:]\n",
    "\n",
    "ef_relu = Trainer(module=ReconModel,\n",
    "             optim=torch.optim.Adam,\n",
    "             lr=0.005,\n",
    "             max_epochs=30,\n",
    "             train_split=my_train_split,\n",
    "             \n",
    "             module__num_modules=32,\n",
    "             module__num_hidden=64,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m1.8167\u001b[0m        \u001b[32m0.8152\u001b[0m  0.5924\n",
      "      2        \u001b[36m0.8063\u001b[0m        \u001b[32m0.3911\u001b[0m  0.6822\n",
      "      3        \u001b[36m0.3626\u001b[0m        \u001b[32m0.2530\u001b[0m  0.6114\n",
      "      4        \u001b[36m0.2260\u001b[0m        \u001b[32m0.1849\u001b[0m  0.7582\n",
      "      5        \u001b[36m0.1709\u001b[0m        \u001b[32m0.1122\u001b[0m  0.6179\n",
      "      6        \u001b[36m0.1120\u001b[0m        \u001b[32m0.0763\u001b[0m  0.6032\n",
      "      7        \u001b[36m0.0816\u001b[0m        0.0988  0.5168\n",
      "      8        0.1019        0.1276  0.6145\n",
      "      9        0.1278        0.1145  0.6470\n",
      "     10        0.1150        \u001b[32m0.0695\u001b[0m  0.7311\n",
      "     11        \u001b[36m0.0724\u001b[0m        \u001b[32m0.0284\u001b[0m  0.6749\n",
      "     12        \u001b[36m0.0337\u001b[0m        \u001b[32m0.0147\u001b[0m  0.6920\n",
      "     13        \u001b[36m0.0209\u001b[0m        0.0253  0.7134\n",
      "     14        0.0307        0.0415  0.5658\n",
      "     15        0.0451        0.0483  0.6004\n",
      "     16        0.0502        0.0440  0.5437\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "ef_relu.fit(X_train[:, :-1], X_train[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_valid\n",
    "pred = ef_relu.predict_proba(data)\n",
    "\n",
    "for i in range(pred.shape[0]):\n",
    "    plt.figure(i)\n",
    "    plt.plot(data[i].numpy())\n",
    "    plt.plot(np.arange(len(pred[i])), pred[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
